{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38] \n",
      " [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
      "Episode : 100 | Reward -> 39.73 | Max reward : 86.0 | Time : 0.0\n",
      "Episode : 200 | Reward -> 44.17 | Max reward : 101.0 | Time : 0.0\n",
      "Episode : 300 | Reward -> 77.63 | Max reward : 165.0 | Time : 0.0\n",
      "Solved in episode : 303 in time 0.0\n",
      "Episode : 400 | Reward -> 87.25 | Max reward : 271.0 | Time : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode : 500 | Reward -> 101.6 | Max reward : 343.0 | Time : 0.017246723175048828\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "\n",
    "# import libraries\n",
    "import gym \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# import pygame\n",
    "\n",
    "# create environment \n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# Define the Q table\n",
    "state_space = 4 # number of states\n",
    "action_space = 2 # number of possible actions\n",
    "\n",
    "print(env.observation_space.low,\"\\n\",env.observation_space.high)\n",
    "def Qtable(state_space,action_space,bin_size = 30):\n",
    "    \n",
    "\n",
    "    bins = [np.linspace(-4.8,4.8,bin_size),\n",
    "            np.linspace(-4,4,bin_size),\n",
    "            np.linspace(-0.418,0.418,bin_size),\n",
    "            np.linspace(-4,4,bin_size)]\n",
    "\n",
    "    q_table = np.random.uniform(low=-1,high=1,size=([bin_size] * state_space + [action_space]))\n",
    "    return q_table, bins\n",
    "\n",
    "def Discrete(state, bins):\n",
    "    index = []\n",
    "    for i in range(len(state)): index.append(np.digitize(state[i],bins[i]) - 1)\n",
    "    return tuple(index)\n",
    "\n",
    "def Q_learning(q_table, bins, episodes = 5000, gamma = 0.95, lr = 0.1, timestep = 50, epsilon =\n",
    "0.2):\n",
    "    rewards = 0\n",
    "    solved = False\n",
    "    steps = 0\n",
    "    runs = [0]\n",
    "    data = {'max' : [0], 'avg' : [0]}\n",
    "    start = time.time()\n",
    "    ep = [i for i in range(0,episodes + 1,timestep)]\n",
    "#     frames = None\n",
    "\n",
    "    for episode in range(1,episodes+1):\n",
    "\n",
    "        current_state = Discrete(env.reset(),bins) # initial observation\n",
    "        score = 0\n",
    "        done = False\n",
    "        temp_start = time.time()\n",
    "        if episode%episodes == 0:\n",
    "            frames = []\n",
    "\n",
    "        while not done:\n",
    "            steps += 1\n",
    "            ep_start = time.time()\n",
    "            \n",
    "#                 env.render()\n",
    "\n",
    "            if np.random.uniform(0,1) < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(q_table[current_state])\n",
    "\n",
    "            if episode%episodes == 0: \n",
    "                frames.append(env.render(mode=\"rgb_array\"))\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            next_state = Discrete(observation,bins)\n",
    "\n",
    "            score += reward\n",
    "\n",
    "\n",
    "            if not done:\n",
    "                max_future_q = np.max(q_table[next_state])\n",
    "                current_q = q_table[current_state+(action,)]\n",
    "                new_q = (1-lr)*current_q + lr*(reward + gamma*max_future_q)\n",
    "                q_table[current_state+(action,)] = new_q\n",
    "\n",
    "            current_state = next_state\n",
    "\n",
    "        # End of the loop update\n",
    "        else:\n",
    "            rewards += score\n",
    "            runs.append(score)\n",
    "            if score > 195 and steps >= 100 and solved == False: # considered as a solved:\n",
    "                solved = True\n",
    "                print('Solved in episode : {} in time {}'.format(episode, (time.time()-ep_start)))\n",
    "\n",
    "        # Timestep value update\n",
    "        if episode%timestep == 0:\n",
    "            print('Episode : {} | Reward -> {} | Max reward : {} | Time : {}'.format(episode,rewards/timestep, max(runs), time.time() - ep_start))\n",
    "            data['max'].append(max(runs))\n",
    "            data['avg'].append(rewards/timestep)\n",
    "            if rewards/timestep >= 195:\n",
    "                print('Solved in episode : {}'.format(episode))\n",
    "            rewards, runs= 0, [0]\n",
    "\n",
    "    # if len(ep) == len(data['max']):\n",
    "    #     plt.plot(ep, data['max'], label = 'Max')\n",
    "    #     plt.plot(ep, data['avg'], label = 'Avg')\n",
    "    #     plt.xlabel('Episode')\n",
    "    #     plt.ylabel('Reward')\n",
    "    #     plt.legend(loc = \"upper left\")\n",
    "    #     plt.show()\n",
    "    return frames\n",
    "#     env.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    q_table, bins = Qtable(len(env.observation_space.low), env.action_space.n)\n",
    "\n",
    "    frames = Q_learning(q_table, bins, lr = 0.15, gamma = 0.995, episodes = 5*10**2, timestep = 100)\n",
    "#     env.close()\n",
    "#     time.wait\n",
    "    save_frames_as_gif(frames)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "for _ in range(100):\n",
    "    img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    action = env.action_space.sample()\n",
    "    env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "import gym \n",
    "\n",
    "\"\"\"\n",
    "Ensure you have imagemagick installed with \n",
    "sudo apt-get install imagemagick\n",
    "Open file in CLI with:\n",
    "xgd-open <filelname>\n",
    "\"\"\"\n",
    "def save_frames_as_gif(frames, path='./', filename='gym_animation.gif'):\n",
    "\n",
    "    #Mess with this to change frame size\n",
    "#     import pdb; pdb.set_trace()\n",
    "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi=72)\n",
    "\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    anim.save(path + filename, writer='imagemagick', fps=60)\n",
    "\n",
    "# #Make gym env\n",
    "# env = gym.make('CartPole-v1')\n",
    "\n",
    "# #Run the env\n",
    "# observation = env.reset()\n",
    "# frames = []\n",
    "# for t in range(1000):\n",
    "#     #Render to frames buffer\n",
    "#     frames.append(env.render(mode=\"rgb_array\"))\n",
    "#     action = env.action_space.sample()\n",
    "#     _, _, done, _ = env.step(action)\n",
    "#     if done:\n",
    "#         break\n",
    "# env.close()\n",
    "# save_frames_as_gif(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
